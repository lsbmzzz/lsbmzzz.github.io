---
layout:     post
title:      支持向量机SVM
subtitle:   支持向量机SVM
date:       2019-09-02
author:     正版慕言
header-img: img/blog_bg_1.jpg
catalog: true
mathjax: true
tags:
    - 支持向量机
    - SVM

---

SVM是建立在统计学的VC维理论和结构风险最小化原理基础上的根据有限的样本信息在模型复杂性和学习能力之间寻找最佳折中来获得最好泛化能力的方法。

简单的理解，用二维空间上的二分类为例，SVM就是找到一条分割线将两类样本分开。如下图，这样的线可能有无数条，但那条是最优的，就是我们要考虑的问题。

![SVM](/img/MachineLearning/西瓜书-6.存在多个超平面.png)

直观上看，最优的划分超平面应该是正中间的那一个，因为该超平面对样本的扰动容忍性最好。

在给定的样本空间$D=\{(x_{1},y_{1}),(x_{2},y_{2}),...,(x_{m},y_{m})\}$中，划分超平面可以通过如下的线性方程表述：

$$\mathbf w^T \mathbf x + b = 0 $$

其中$\mathbf w = (w_1, w_2,..., w_d) $为法向量，它和偏置b一起决定了超平面的位置。我们可以记为$(\mathbf w, b)$。

样本空间中的任意点到超平面的距离为

$$\begin{equation}
r=\frac{|w^{T}x+b|}{||w||}
\end{equation}$$

$$ \| \mathbf w\| $$为欧几里得范数

假设超平面能将样本正确分类，那么有$\mathbf w^T\mathbf x_i + b < 0 $令

$$
\left\{\begin{matrix}
w^{T}x_{i}+b\geq +1, & y_{i}=+1 \\ 
w^{T}x_{i}+b\leq -1, & y_{i}=-1
\end{matrix}\right.
$$

距离超平面最近的训练点使等号成立，它们叫做**支持向量**。

两个异类支持向量到超平面的距离之和称为**间隔**：

$$\begin{equation}
\gamma =\frac{2}{||w||}
\end{equation}$$

要找到具有最大间隔的超平面，就是要能找到让$\gamma$最大的$\mathbf w$和$b$。

$$\max_{\mathbf w, b}\frac{2}{\| \mathbf w\|} , y_i(\mathbf w^T\mathbf x_i + b) \geqslant 1 $$

可以看出，为了最大化间隔，只要最大化$\|\|\mathbf w\|\|^{-1} $，等价于最小化$\|\|\mathbf w\|\|^2$。因此上式可以转化为

$$\min_{\mathbf w, b}\frac{1}{2}\|\mathbf w\|^2 $$

这就是支持向量机的基本模型。
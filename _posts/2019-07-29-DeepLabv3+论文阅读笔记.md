---
layout:     post
title:      DeepLabv3 plus 论文阅读笔记
subtitle:   Xception: Deep Learning with Depthwise Separable Convolutions 阅读笔记
date:       2019-07-29
author:     正版慕言
header-img: img/blog_bg_1.jpg
catalog: true
tags:
    - 深度学习
    - DeepLabv3+
    - 论文笔记

---


> 论文链接 ： [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)
> ![DeepLabv3+题目.png](/img/DeepLabv3+题目.png)

**摘要** 空间金字塔结构和编码器-解码器结构都是深度学习解决语义分割问题常用的结构。空间金字塔结构可以在输入数据上进行多采样率的卷积和池化，达到编码feature map多尺寸信息的效果。编码器-解码器结构能够通过恢复数据的空间信息来获得分割对象的边界。这篇文章结合了二者的优点，在DeepLabv3上增加了一个解码器模块，提出了**DeepLabv3+** 。进一步探讨了Xception模型，**将深度分离卷积应用到空间金字塔和解码器模块上** ，提高模型的性能。

#### 介绍
DeepLabv3中使用的两种神经网络的特点：

* 空间金字塔：能够通过在不同分辨率上进行卷积和池化操作获得更丰富的上下文信息
* 编码器-解码器结构：获得清晰的物体边界。

DeepLabv3+在DeepLabv3基础上增加了一个用来恢复便捷信息的模块。
![DeepLabv3+模型对比.png](/img/DeepLabv3+模型对比.png)

* (a)是DeepLabv3的结构，先用空间金字塔结构采集上下文信息，然后直接上采样获得预测结果。
* (b)是编码器-解码器结构
* (c)是DeepLabv3+的结构，用DeepLabv3做编码器，解码器采用了简化版的（b）中解码器的结构用来获得更详细的边界信息。

在此基础上受Xception启发，将深度分离卷积应用到空间金字塔和解码器模块上，用以加速模型训练并保证其学习能力。

论文的亮点：

1. 基于DeepLabv3提出了一种全新的编码器-解码器结构；
2. 该模型能够通过空洞卷积直接控制编码器提取特征的分辨率；
3. 将Xception的深度分离卷积应用到空间金字塔和解码器模块，获得性能更高的模型；
4. 开源。链接：[DeepLabv3+](https://github.com/fourmi1995/IronSegExperiment-Deeplabv3_PLUS)

#### 相关技术

* 空间金字塔池化
* 编码器-解码器
* 深度分离卷积

#### 方法

***1. 使用了空洞卷积和深度分离卷积的编码器-解码器结构***
    1. 深度分离卷积：将标准的卷积操作分解成深度卷积。**深度卷积对输入feature map的每一个通道独立进行卷积**，然后对深度卷积获得的feature map进行1x1的卷积，从而降低计算的复杂度。
    2. 在空洞卷积中引入了深度分离卷积的支持，称为“空洞可分卷积”。这种结构显著降低了模型计算的复杂度，并能够获得近似（或更好）的性能。
    3. **编码器使用DeepLabv3结构** ，DeepLabv3使用空洞卷积提取不同分辨率的特征。根据图像分类和分割任务的不同，去掉了最后一个卷积中的步长，用空洞卷积获得更密集的特征（DeepLabv3为8倍，endocer-decoder为32倍，DeepLabv3+为16倍）。**解码器增加了一个中间层** ，先进行一次4倍的上采样，用3x3的卷积细化特征之后再进行第二次4倍的上采样。

![DeepLabv3+.png](/img/DeepLabv3+.png)

![深度分离卷积.png](/img/深度分离卷积.png)

***2. 用分离卷积改进Xception***
Xception在图像分类方面具有快速计算的能力，这篇文章修改了Xception模型使之能够适应图像分割任务：

1. 加深了Xception结构
2. 将所有的池化层替换成了带步长的深度分离卷积
3. 对每一次3x3的卷积结果进行BatchNormalization标准化和ReLU激活

![Xception的改进.png](/img/Xception的改进.png)

**用改进以后的Xception替换了原本DeepLabv3中的编码器**，获得DeepLabv3+。

#### 实验评估部分

***1. 解码器的设计中，进行了一些讨论。*** 用实验证明以下三种方法能够提高模型的性能。

* 
    * 用1x1的卷积减少feature map的通道数
        ![1x1减少通道数.png](/img/1x1减少通道数.png)
    
    * 使用3x3的卷积细化上采样特征
        ![3x3细化特征.png](/img/3x3细化特征.png)
        
    * 使用低维度特征来帮助获得更多细节
        ![低维度弥补特征.png](/img/低维度弥补特征.png)

***2. 用ResNet-101（DeepLabv3的结构） 和 Xception 做编码器的实验对比。***
1. 用ResNet-101做编码器
* ![ResNet-101实验对比.png](/img/ResNet-101实验对比.png)
* 测试了3种变体：没有使用decoder（用作基础对比）、使用decoder、下采样32倍。
2. 用Xception做编码器
* ![Xception实验对比.png](/img/Xception实验对比.png)
* 用五组实验做对比：没有使用decoder（作为基础对比）、使用了decoder的、增加了深度分离卷积的、在COCO数据集上进行了预训练的、在JFT数据集上进行了预训练的

训练效果的对比：
![DeepLabv3+四种模型的训练效果.png](/img/DeepLabv3+四种模型的训练效果.png)
使用了decoder的模型效果更好，Xception的效果比ResNet-101更好。

#### 结论
本文提出的DeepLabv3+采用了编码器-解码器结构，用DeepLabv3座编码器来丰富上下文信息，设计了一个简单的解码器来恢复数据的边界信息；还探讨了Xception模型和深度分离卷积使模型性能更高。
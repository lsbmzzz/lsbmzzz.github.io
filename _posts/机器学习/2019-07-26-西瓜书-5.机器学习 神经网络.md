---
layout:     post
title:      5.机器学习|神经网络
subtitle:   机器学习周志华 学习笔记————机器学习|神经网络
date:       2019-07-26
author:     正版慕言
header-img: img/blog_bg_3.jpg
catalog: true
tags:
    - 机器学习
    - 西瓜书

---

> **神经网络的定义** 神经网络是由具有适应性的简单单元组成的广泛并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所做出的交互反应。

神经网络中最基本的单位是**神经元模型**。1943年，McCulloch和Pitts设计了一种简单的模型“M-P神经元模型”，一直沿用至今。
![西瓜书-5.M-P神经元模型](/img/机器学习/西瓜书/西瓜书-5.M-P神经元模型.png)
神经元的输出为
![西瓜书-5.M-P神经元的输出](/img/机器学习/西瓜书/西瓜书-5.M-P神经元的输出.gif)
其中f为激活函数。典型的激活函数有阶跃函数、Sigmoid函数、ReLU、LeakyReLU等。
![西瓜书-5.典型激活函数.png](/img/机器学习/西瓜书/西瓜书-5.典型激活函数.png)

#### 感知机与多层网络
**感知机** 由两层神经元组成，能容易的实现逻辑与、或、非的运算。
![西瓜书-5.两个输入神经元的感知机.png](/img/机器学习/西瓜书/西瓜书-5.两个输入神经元的感知机.png)
感知机的权重调整：
![西瓜书-5.感知机权重调整.gif](/img/机器学习/西瓜书/西瓜书-5.感知机权重调整.gif)
可以看出，若果感知机对样例（**x**, y）的预测正确，不会调整权重；如果预测错误，会根据错误程度进行权重调整。

感知机只有输出层进行激活处理，其学习能力有限。
感知机甚至不能解决异或问题。

**多层前馈神经网络** 只要包含隐层，就可以称为多层网络。![西瓜书-5.多层前馈神经网络.png](/img/机器学习/西瓜书/西瓜书-5.多层前馈神经网络.png)

#### 误差逆传播算法（BP）
BP算法的工作流程

1. 在（0， 1）范围内随机初始化网络中所有链接的权和阈值
2. 根据当前参数计算样本输出：
    * ![西瓜书-5.BP输出.gif](/img/机器学习/西瓜书/西瓜书-5.BP输出.gif)
3. 计算输出层神经元的梯度项
    * ![西瓜书-5.BP输出神经元的梯度项.gif](/img/机器学习/西瓜书/西瓜书-5.BP输出神经元的梯度项.gif)
4. 计算隐层神经元的梯度项
    * ![西瓜书-5.BP隐层神经元的梯度项.gif](/img/机器学习/西瓜书/西瓜书-5.BP隐层神经元的梯度项.gif)
5. 更新连接权ωhj, vih, 与阈值θj, γh。
    * ![西瓜书-5.连接权与阈值更新.gif](/img/机器学习/西瓜书/西瓜书-5.连接权与阈值更新.gif)
6. 循环第2-5步直到达到停止条件，输出连接权与阈值确定的多层前馈神经网络。

BP算法的目标是最小化训练集D上的累积误差
![西瓜书-5.累积误差.gif](/img/机器学习/西瓜书/西瓜书-5.累积误差.gif)

**标准BP算法和累积BP算法**：标准BP算法每次更新只针对单个样例，累积BP算法直接针对累积误差最小化。
二者的优缺点：
1. 标准BP算法参数更新频繁，而且对不同样例进行的更新可能会“抵消”。累积BP算法在读取整个训练集D一遍后才更新参数。
2. 在很多任务中，累积误差下降到一定程度后，进一步的下降会非常缓慢，这时候标准BP旺旺能更快的得到较好的解。

BP神经网络由于其强大的学习能力经常遭遇过拟合，有两种策略来缓解过拟合：
1. 早停：如果误差训练集降低但验证集升高，则停止训练。
2. 正则化：基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分（例如连接权与阈值的平方和）

#### 全局最小与局部极小
局部极小解：参数空间中的某个点，其邻域点的误差函数值均不小于该点的误差函数值。
全剧最小解：参数空间中的所有点的误差函数值距不小于该点的误差函数值。

梯度下降是使用最广发的参数寻优方法。当误差函数有多个局部极小的时候，搜索到的解可能就不是最优解。
在现实任务中常用的调出局部极小解的方法：
1. 用多组不同的参数初始化多个不同的神经网络，选择最优。
2. 使用“模拟退火”。模拟退火在每一步都有一定的概率接受比当前解更差的结果，从而有助于跳出极小。在迭代中，接受“次优解”的概率应逐渐下降。
3. 使用随机梯度下降。在计算梯度中加入了随机因素，这样在陷入局部极小时梯度仍可能不为0，有助于跳出局部极小解。

#### BP以外其他常见的神经网络
1. RBF网络：一种单隐层的前馈神经网络，使用径向基函数作为隐层神经元的激活函数，输出层是对隐层神经元输出的线性组合。
2. ART网络：一种竞争型学习网络。包含比较层、识别层、识别阈值和重置模块。
3. SOM网络：一种竞争型学习的无监督神经网络，能将高维输入数据映射到低维空间，同时保持输入数据在高维空间的拓扑结构。
4. 级联相关网络：一种结构自适应网络。
5. Elman网络：一种常用的递归神经网络。
6. Boltzmann机：一种“基于能量的模型”

#### 深度学习
很深层的神经网络
训练策略：
1. 预训练+微调
2. 权值共享
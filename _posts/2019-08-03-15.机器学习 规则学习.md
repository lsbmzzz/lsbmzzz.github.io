---
layout:     post
title:      15.机器学习|规则学习
subtitle:   机器学习周志华 学习笔记————机器学习|规则学习
date:       2019-08-03
author:     正版慕言
header-img: img/blog_bg_3.jpg
catalog: true
tags:
    - 机器学习
    - 西瓜书

---

#### 基本概念
机器学习中的“规则”通常是指语义明确、能描述数据分布所隐含的客观规律或领域概念、可写成“若……，则……”形式的逻辑规则。
“规则学习”是从训练数据中学习出一组能用于对未见示例进行判别的规则。
![西瓜书-15.一条规则.gif](/img/西瓜书-15.一条规则.gif)
上面的一条规则中，左侧称为规则头，右侧称为规则体，L为规则长度。这样的规则也被称为“if-then”规则。

与神经网络、支持向量机等“黑盒模型”相比，规则学习具有更好的可解释性。

规则集合中的每条规则都可以看做一个子模型，规则集合是这些子模型的一个集成。
当同一个示例被判别结果不同的多条规则覆盖时，我们说发生了“冲突”。
解决冲突的方法：

* 投票法：将判别相同的规则数最多的结果作为最终结果。
* 排序法：在规则集合上定义一个顺序，发生冲突时使用最前面的规则。相应的规则学习过程称为“带序规则”学习或“优先级规则”学习。
* 元规则法：根据领域知识事先设定一些“元规则”，即关于规则的规则，根据元规则的指导来使用规则集。

从训练集学得的规则也许不能覆盖所有可能的未见示例。因此，学习算法通常会设置一条“默认规则”，用来处理规则集合未覆盖的样本。

从形式语言表达能力来说，规则可以分为“命题规则”和“一阶规则”两类。

* 命题规则是由“原子命题”和逻辑连接词“与”“或”“非”“蕴含”构成的简单陈述句
* 一阶规则的基本成分是能描述事物的属性或关系的“原子公式”。

一阶规则能表达复杂的关系，因此也被称为“关系型规则”。
从语言系统的角度看，命题规则是一阶规则的特例，因此一阶规则的学习比命题规则要复杂得多。

#### 序贯覆盖
规则学习的目标是产生一个能覆盖尽可能多的样例的规则集，最直接的做法是“序贯覆盖”，即逐条归纳：在训练集上每学到一条规则，就将该规则覆盖的训练样例去除，然后以剩下的训练样例组成训练集重复上述过程。由于每次只处理一部分数据，因此也被称为“分治”策略。

关键在于如何从训练集学出单条规则。

1. 基于穷尽搜索的方法：从空规则开始，将正例类别作为规则头，再逐个遍历训练集中的每个属性及取值，尝试将其作为逻辑文字增加到规则体中，若能使当前规则体仅覆盖正例，则由此产生一条规则，然后去除已被覆盖的正例并基于剩余样本尝试生成下一条规则。
2. 自顶向下：从比较一般的规则开始，逐渐添加新文字以缩小规则覆盖范围，直到满足条件为止。也叫作“生成-测试”法，是规则逐渐“特化”的过程。
3. 自底向上：从比较特殊的规则开始，逐渐删除文字以扩大规则覆盖范围直到满足条件为止。也叫作“数据驱动”法，是规则逐渐“泛化”的过程。

自顶向下策略是覆盖范围从大往小的搜索规则，通常更容易产生泛化性能较好的规则，对噪声的鲁棒性更强。而自底向上策略在一阶学习这类假设空间非常复杂的任务上使用较多。

#### 剪枝优化
规则生成本质上是一个贪心搜索的过程，需要有一定的机制来缓解过拟合风险，最常见的做法就是剪枝。

* 预剪枝：发生在规则产生过程中
* 后剪枝：发生在规则产生后

剪枝通常是寄予某种性能度量指标来评估增/删逻辑文字前后的规则性能，或增/删规则前后的规则集性能，从而判断是否要进行剪枝。

剪枝还可以借助统计显著性检验来进行，例如CN2算法：在剪枝时，假设用规则集进行预测必须显著优于直接基于训练样例集后验概率分布进行预测。为了便于计算，使用了似然统计量LRS。令m+,m-分别表示训练样例集中的正反例数目，m^+,m^-表示规则及覆盖的正反例数目，有
![西瓜书-15.LRS.gif](/img/西瓜书-15.LRS.gif)
LRS越大，采用规则集进行预测与直接使用训练集正反例比例进行猜测的差别越大。
LRS越小，规则及的效果越可能是偶然现象。

后剪枝最常用的策略是“减错剪枝”（REP）:将样例集划分成训练集和验证集，从训练集上学得规则及R后进行多轮剪枝，每一轮穷举所有可能的剪枝操作，然后用验证集对剪枝产生的所有候选规则集进行评估，保留最好的那个进行下一轮剪枝。REP通常很有效，但复杂度达到O(m4)。

IREP将复杂度降到了O(mlog^2 m)：生成每条规则前，将样例集划分为训练集和验证集，每生成一条规则后立刻在验证集上进行REP剪枝得到规则，并将覆盖样例去除。

RIPPER（预剪枝+后处理优化）：先用IREP* 剪枝机制生成规则集R，对R中的每条规则，为其产生两个变体：

* ri'：基于ri覆盖的样例，用IREP* 重新生成一条规则ri'，该规则称为替换规则
* ri''：对ri增加文字进行特化，然后再用IREP* 剪枝生成一条规则ri''，该规则称为修订规则

将原规则集合新规则集分别进行评估，保留最好的。
![西瓜书-15.RIPPER算法.png](/img/西瓜书-15.RIPPER算法.png)

#### 一阶规则学习
命题规则学习受限于其逻辑表达能力，有时候难以处理对象之间的“关系”。

一阶规则学习能够容易的引入领域知识，这是它相对于命题规则学习的另一个优势。

FOIL是著名的一阶规则学习算法，遵循序贯覆盖框架，采用自顶向下的规则归纳策略。
FOIL使用“FOIL增益”来选择文字：
![西瓜书-15.FOIL增益.gif](/img/西瓜书-15.FOIL增益.gif)
FOIL可以看作是命题规则学习和归纳逻辑程序设计之间的过渡，但其自顶向下的规则生成过程不支持嵌套，因此规则表达能力仍有不足。

#### 归纳逻辑程序设计
归纳逻辑程序设计（LLP）在一阶规则学习中引入了函数和逻辑表达式嵌套

1. 最小一般泛化
归纳逻辑程序设计采用自底向上的规则生成策略，直接将一个或多个正例所对应的具体事实作为初始规则，再对规则逐步进行泛化以增加其对样例的覆盖率。泛化操作可以是将规则中的常量替换为逻辑变量，也可以是删除规则体中的某个文字。
最小一般泛化（LGG）：

    * 给定一阶公式r1,r2
    * 找出涉及相同谓词的文字
    * 对文字中每个位置的常量逐一考察，如果在两个文字中相同则保持不变，否则将它们替换为同一个新变量
    * 忽略r1和r2中不含共同谓词的文字，得到不包含常量的一般规则

RLGG在计算LGG时考虑所有的背景知识

2. 逆归结
一阶谓词演算中的演绎推理能用一条十分简洁的规则描述，这就是数理逻辑中著名的归结原理。
基于归结原理我们可以将复杂的逻辑规则与背景知识联系起来化繁为简；基于逆归结，我们可以基于背景知识来发明新的概念和关系。

形式化定义：
假定两个逻辑表达式C1和C2成立，分别包含互补项L1和L2。令L = L1 = ┐L2，C1 = A ∨ L，C2 = B∨┐L.
如果定义析合范式的删除操作(A∨B)-B=A
归结过程可以表述为C=(C1-{L})∨(C2-{┐L})
逆归结可以表述为C2=(C-(C1-{L}))∨{┐L}

逆归结的四种操作：吸收、辨识、内构、互构
![西瓜书-15.逆归结的4种操作.png](/img/西瓜书-15.逆归结的4种操作.png)

归结和逆归结都能容易的扩展为一阶逻辑形式。与命题逻辑的主要不同在于一阶逻辑的归结和逆归结通常需要进行合一置换操作。

* 置换：用某些项来替换逻辑表达式中的变量
* 合一：用一种变量置换令两个或多个逻辑表达式相等

逆归结的一大特点是能够自动发明新谓词，这些新谓词可能对应于样例属性和背景知识中不存在的新知识，对知识发现与精化有重要意义。
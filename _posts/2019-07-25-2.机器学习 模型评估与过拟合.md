---
layout:     post
title:      2.机器学习|模型评估与过拟合
subtitle:   机器学习周志华 学习笔记————机器学习|模型评估与过拟合
date:       2019-07-25
author:     正版慕言
header-img: img/blog_bg_3.jpg
catalog: true
tags:
    - 机器学习
    - 西瓜书
    - 模型评估

---

**过拟合：** 模型将训练样本学得“太好”，可能将训练样本的一些自身的特点当做了所有数据的一般性质，导致泛化性能的下降。

**欠拟合:** 对训练样本的一般性质还没有学好。

欠拟合的解决方案：在决策树中扩展分支、在神经网络中增加训练轮数等。

**过拟合是机器学习面临的关键障碍。** 过拟合无法彻底避免，只能缓解。类比NP问题（只要有P ≠ NP，过拟合就无法避免）

#### 评估方法
1. 留出法：划分训练集和测试集
2. 交叉验证法（k折交叉验证）。
    1. 留一法：当包含m个样本，而k = m。留一法是交叉验证法的特例。
3. 自助法：**对数据集D，采样得到数据集D'：** 每次从D中随机挑选一个样本，将其拷贝放入D'，执行m次，就得到了包含m个样本的D'。
    * 估计：样本在m次采样中始终不出现的概率为![自助法公式](/img/评估方法自助法.png)
    * 将D'用作训练集，D\D'（D中除去D'）用作测试集。
4. 调参：基于验证集上的性能进行调参。

#### 性能度量
**性能度量：衡量模型泛化能力的评价标准**
1. 错误率与精度

2. 查准率、查全率与F1
    * ![分类结果混淆矩阵](/img/分类结果混淆矩阵.png)
    * 查准率（Precision） ![查准率](/img/查准率.gif)
    * 查全率（Recall） ![查全率](/img/查全率.gif)
    * PR曲线样例![PR曲线](/img/PR曲线样例.png)
    * F1度量：![F1度量](/img/F1度量.gif)（N为样例总数）
    * ![Fβ](/img/Fβ.gif)（β > 0度量了查全率对于查准率的相对重要性。β  > 1时查全率影响更大，β < 1时查准率影响更大）
    
3. ROC与AUC
    * ROC：受试者工作特征。
        * 纵轴是“真正例率”：![TPR](/img/TPR.gif)
        * 横轴是“假正例率”：![FPR](/img/FPR.gif)
    * AUC：ROC曲线的下面积。![AUC](/img/AUC.gif)
    * ![ROC与AUC](/img/ROC与AUC.png)
    
4. 代价敏感错误率与代价曲线：最小化“整体代价”，而非“错误次数”。

#### 比较检验
1. 我们希望比较的是泛化性能，而实验评估集上得到的是测试集上的性能
2. 测试集上的性能和测试机本身的选择有很大关系
3. 很多机器学习算法本身就具有一定的随机性

**统计假设检验**
    基于假设检验的结果，我们可以推断出若测试集上观察到的模型A比B好，则A的泛化性能是否在统计意义上优于B以及这个结论的把握有多大。
    
1. **假设检验**：根据测试错误率估推出泛化错误率的分布
2. **交叉验证t检验**：在k折交叉验证中，可以使用k折交叉验证“成对t检验”进行比较检验。
    * **5x2交叉验证**：每次2折交叉验证之前随机将数据打乱，使5次交叉验证中的数据划分不重复。仅计算第一次二折交叉验证的两个结果的平均值
    ![平均值](/img/二折交叉验证平均值.gif)
    但对每次二折验证的结果都计算其方差
    ![方差](/img/5次2折交叉验证方差.gif)。
3. **McNemar检验**：考虑变量
	![](/img/McNemar检验.gif)
	服从自由度为1的χ^2分布
4. **Friedman检验和Nemenyi后续检验**：在一组数据集上对多个算法进行比较

#### 偏差与方差
**偏差—方差分解**：解释学习算法泛化性能的一种重要工具.
泛化误差可以分解为偏差、方差与噪声之和。
![泛化误差](/img/泛化误差.gif)
![贝叶斯偏差](/img/贝叶斯偏差.gif)
![方差](/img/方差.gif)
![噪声](/img/噪声.gif)

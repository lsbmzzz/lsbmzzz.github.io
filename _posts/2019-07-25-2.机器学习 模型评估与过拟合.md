---
layout:     post
title:      2.机器学习|模型评估与过拟合
subtitle:   机器学习周志华 学习笔记————机器学习|模型评估与过拟合
date:       2019-07-25
author:     正版慕言
header-img: img/blog_bg_3.jpg
catalog: true
tags:
    - 机器学习
    - 西瓜书

---

**过拟合：** 模型将训练样本学得“太好”，可能将训练样本的一些自身的特点当做了所有数据的一般性质，导致泛化性能的下降。
**欠拟合:** 对训练样本的一般性质还没有学好。

欠拟合的解决方案：在决策树中扩展分支、在神经网络中增加训练轮数等。

**过拟合是机器学习面临的关键障碍。** 过拟合无法彻底避免，只能缓解。类比NP问题（只要有P ≠ NP，过拟合就无法避免）

#### 评估方法
1. 留出法：划分训练集和测试集
2. 交叉验证法（k折交叉验证）。
    1. 留一法：当包含m个样本，而k = m。留一法是交叉验证法的特例。
3. 自助法：**对数据集D，采样得到数据集D'：** 每次从D中随机挑选一个样本，将其拷贝放入D'，执行m次，就得到了包含m个样本的D'。
    * 估计：样本在m次采样中始终不出现的概率为![自助法公式](/img/评估方法自助法.png)
    * 将D'用作训练集，D\D'（D中除去D'）用作测试集。
4. 调参：基于验证集上的性能进行调参。

#### 性能度量
**性能度量：衡量模型泛化能力的评价标准**
1. 错误率与精度

2. 查准率、查全率与F1
    * ![分类结果混淆矩阵](/img/分类结果混淆矩阵.png)
    * 查准率（Precision） P = ${TP} \over {TP + FP}$
    * 查全率（Recall） R = ${TP} \over {TP + FN}$
    * PR曲线样例![PR曲线](/img/PR曲线样例.png)
    * F1度量：F1 = ${2PR} \over{P + R}$ = ${2TP}\over{N + TP - TN}$（N为样例总数）
    * Fβ = ${(1 + β^2)PR}\over{(β^2P) + R}$（β > 0度量了查全率对于查准率的相对重要性。β  > 1时查全率影响更大，β < 1时查准率影响更大）
    
3. ROC与AUC
    * ROC：受试者工作特征。
        * 纵轴是“真正例率”：TPR = ${TP}\over{TP + FN}$
        * 横轴是“假正例率”：FPR = ${FP}\over{TN + FP}$
    * AUC：ROC曲线的下面积。AUC = ${{1}\over{2}}{\sum^{x_{i+1}}_{i=1}}(x_{i+1}-x_i)·(y_i + y_{i+1})$
    * ![ROC与AUC](/img/ROC与AUC.png)
    
4. 代价敏感错误率与代价曲线：最小化“整体代价”，而非“错误次数”。

#### 比较检验
1. 我们希望比较的是泛化性能，而实验评估集上得到的是测试集上的性能
2. 测试集上的性能和测试机本身的选择有很大关系
3. 很多机器学习算法本身就具有一定的随机性

**统计假设检验**
    基于假设检验的结果，我们可以推断出若测试集上观察到的模型A比B好，则A的泛化性能是否在统计意义上优于B以及这个结论的把握有多大。
    
1. **假设检验**：根据测试错误率估推出泛化错误率的分布
2. **交叉验证t检验**：在k折交叉验证中，可以使用k折交叉验证“成对t检验”进行比较检验。
    * **5x2交叉验证**：每次2折交叉验证之前随机将数据打乱，使5次交叉验证中的数据划分不重复。仅计算第一次二折交叉验证的两个结果的平均值μ = 0.5(Δ_1^1+Δ_1^2)，但对每次二折验证的结果都计算其方差$σ_i^2 = 0.5({Δ_i^1 - {{Δ_i^1 + Δ_i^2}\over{2}}})^2 + {(Δ_i^2-{{Δ_i^1+Δ_i^2}\over{2}})^2}$。
3. **McNemar检验**：考虑变量$τ_{χ^2} = {{(|e_{01}-e_{10}|-1)^2}\over{e_{01}+e_{10}}}$服从自由度为1的χ^2分布
4. **Friedman检验和Nemenyi后续检验**：在一组数据集上对多个算法进行比较

#### 偏差与方差
**偏差—方差分解**：解释学习算法泛化性能的一种重要工具.
泛化误差可以分解为偏差、方差与噪声之和。
$E(f;D) = bias^2(\bm{x}) + var(\bm{x}) + ε^2$
$bias^2(\bm{x}) = (\bar{f}(\bm{x})-y)^2$
$var(\bm{x}) = \bm{E_D}[(f(\bm{x};D)-\bar{f}(\bm{x}))^2]$
$ε^2 = \bm{E_D}[(y_D-y)^2]$

